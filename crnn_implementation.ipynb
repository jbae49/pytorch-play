{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "XsLJbepk8vAf"
      },
      "outputs": [],
      "source": [
        "# importing the zipfile module\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# loading the temp.zip and creating a zip object\n",
        "with ZipFile(\"sample_cropped.zip\", 'r') as zObject:\n",
        "\n",
        "\t# Extracting all the members of the zip\n",
        "\t# into a specific location.\n",
        "\tzObject.extractall(\n",
        "\t\tpath=\"sample_training\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as T\n",
        "from torchvision.io import read_image\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "  def __init__(self, img_dir, transform=None, target_transform=None):\n",
        "    #.DS_Store error later with UnidentifiedImageError\n",
        "    self.img_labels = [f for f in os.listdir(img_dir) if f.lower().endswith(('.png','.jpg','jpeg')) and not f.startswith('.')]\n",
        "    self.img_dir = img_dir\n",
        "    # \"During training, all images are scaled to 100 x 32 in order to accelerate the training process.\"\n",
        "    self.transform = T.Compose([\n",
        "        T.Resize((32,100)),\n",
        "        # Input: W x 32 gray-scale image\n",
        "        T.Grayscale(),\n",
        "        T.ToTensor()\n",
        "    ])\n",
        "    self.target_transform = target_transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.img_labels)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_path = os.path.join(self.img_dir, self.img_labels[idx])\n",
        "\n",
        "\n",
        "    image = Image.open(img_path)\n",
        "\n",
        "    label = self.img_labels[idx].split('.')[0].replace('{slash}','/')\n",
        "    if self.transform:\n",
        "      image = self.transform(image)\n",
        "    if self.target_transform:\n",
        "      label = self.target_transform(label)\n",
        "\n",
        "    return image, label"
      ],
      "metadata": {
        "id": "DQV_EmNK9eaY"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customdata = CustomImageDataset(\"train\")"
      ],
      "metadata": {
        "id": "oeiXoEyM88m0"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(customdata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90B0YDhERmdl",
        "outputId": "7c60fc37-083d-4ff4-c39a-2b9be7171d1a"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "162"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(customdata.__getitem__(1)[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CLAygnkRopi",
        "outputId": "818bcc00-6c80-4851-a257-bee689a3a234"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "customdata.__getitem__(1)[0].size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yf-0JyaDRq1p",
        "outputId": "e245def9-4cad-413a-9502-b076885c9c3c"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 32, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_img = customdata.__getitem__(20)[0]\n",
        "tr = T.ToPILImage()\n",
        "img = tr(sample_img)\n",
        "img # not img.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "HhTYdBVnSiHU",
        "outputId": "49b7db98-435e-4be7-c7bd-a413137f5c24"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=100x32>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAAAgCAAAAADBQILyAAAEpklEQVR4nL1WS5IlSQ4C5JFtNve/1tyn8rkEs3CPrK42m23HKv4IfRD8LwCW4Ih09vf3WqsK4+4p1fPFIMFacOyUSHgMkootKQECAEmCAGQVz2kQQPgXjgWAlJDgBOOOV+jc0EIqBoIkOO+ddwlSvLfPNQggIOLD5IAEoiSY54Ztj6EQJMwEUgAmcW4oCEiC0P1/AiKMzkPESZITyGVC5WIkjgkVz+tJQAWBE182P0wONnJABJIHMXYS5NxYC6SA2CRi2wELJw/nb2QQxzaAiOIBmkvvMqFFkUBgXyokJawCSCb5DRIloE6zHMaJZ2yAdZJCIDnYlxqp1KlL4vmDyc2ibRDxzCAARSrx7yROzwzJSKcpE7/0eEGKLBKJZzsIQiGFpdgJZg+I+LObkkonJwBgdu/u9pikWRVBcbrHc2oaBKwAIuHu74+B8E0XkZl4esjEe3eJqgJPohHDe+9u+4DYXmAy+9MzpC4IVsAiMbM/v8zbGRRW4t22Z8hkdjdBSU5shEAG+7On45A0ZxlU4t67d1WxgMQIKJOY3nubAs/MYO18f2/HiZiZvbtO/O5uKoHjvXsMEoRDF1WO3b0bosjAyZA1BHr3BBJ5G2PtfP/aDsgos3fvFZJx9+4Ck8z07oRi6BlUqZzE0711RgCIAa5RsD97QhYEJxmsTz7ffZJJwHYCAvB0NwQwsW2QUsLYcT1GYscGVQu2xqBnEnR3QElCJzHWJ3tM1lpSctqUQDIzUwFJnu5UyWnG8ExOV1XW86wFD+aMTpzpJlWLQmIg6zu7Xar1qOwuieSdmHFAilSBqpInzAQ9JviCPAtT6WaS2J6ZYlVJSMxk7UxYz/N8qeyemStbyVErQpIiSUKIZHBySglr1XoWNC0FPyioV9WRZHUiPX89zyPZTlw6gnXUJgHLBsUkIX70HqSoqqoFso7o5yRtAlCFmXGyGmR9/fWsR6fEs/iC/OyTMkDCP9HddSKkqqpI1BtSghgGpbAvCJfWep6SmHqml5jgCEQ8c/Ur8Lu3eCUdJEgAYnRDupl+NYlSIcsoVq3i0bPSSctR7Uz3Ll4xPKsLBG4DJjr7CbiszylISaoipTLWMKq1CgCgqiqculJE3N0Q7czEEXn0VjwuAXf74t3Vd/np1IpmxVhFIdNHBUDER8fx9lhs7E8nlEiUzor729qFad+JestZVauWRjaxvliZrXzpYrTImDnfkMzM53uk9fUVuK+ikDktS8UY+wUhSEq1ai1xkGD9hWA2uOqE5l5ifEsKkO7969c8X/r6jz297bHn7BvHKjhjQz8eRipJaz0SYWQJ9hD1bCQ9vRt6W/UnZ7bzx2FD+LEU+anLWcJlIh5Q0zODBQCe7L0CT+/dqMlxIddOHVbJ9Nn0zrVat5vI1+uc2akVuClb4+nBIhAjvSvwzO5m159MrmPzAXlR3tj/PChxrcxAe4q2p7EKMeGZTuzpsQO8/gm/Ry/x/N3fnQf8JwhV8wBmnNCxgbXOh55xbM9pxuNAQoR8FcaeZHxNEG6OyN+BRARVK/AkZniUdK1knHj6gMwZ4BN7/skE9iuO/4eJVAuZdny9yL/k6v8HVkf2PLVWulcAAAAASUVORK5CYII=\n"
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "customdata.__getitem__(20)[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qgbSM1sGUwr8",
        "outputId": "45c10ec5-4b2e-4cd8-ee8a-f29b2df4b00c"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'diane'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://stackoverflow.com/questions/50544730/how-do-i-split-a-custom-dataset-into-training-and-test-datasets\n"
      ],
      "metadata": {
        "id": "8EEt6zz3XSQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "batch_size = 8\n",
        "validation_split = .2\n",
        "shuffle_dataset = True\n",
        "random_seed = 42\n",
        "\n",
        "dataset_size = len(customdata)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split * dataset_size))\n",
        "if shuffle_dataset:\n",
        "  np.random.seed(random_seed)\n",
        "  np.random.shuffle(indices)\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)"
      ],
      "metadata": {
        "id": "uxM1dAV7XAW4"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(customdata, batch_size=batch_size, sampler=train_sampler)\n",
        "test_dataloader = DataLoader(customdata, batch_size=batch_size, sampler=valid_sampler)"
      ],
      "metadata": {
        "id": "9KybSTzoWBdJ"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for d, l in train_dataloader:\n",
        "  print(d.size()) # (N, C, H, W)\n",
        "  print(l)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5triDi83d_FJ",
        "outputId": "9325f1de-7353-4adf-ddef-c47ff20bba60"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 1, 32, 100])\n",
            "('British', 'wrox', 'Gt', '150', 'STREET', 'BURNSIDE', 'with', 'Bequet')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "class CRNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\n",
        "    self.conv1 = nn.Conv2d(1, 64, (3,3),1,1)\n",
        "    self.maxpool1 = nn.MaxPool2d((2,2),2)\n",
        "    self.conv2 = nn.Conv2d(64, 128, (3,3), 1, 1)\n",
        "    self.maxpool2 = nn.MaxPool2d((2,2), 2)\n",
        "    self.conv3 = nn.Conv2d(128, 256, (3,3), 1, 1)\n",
        "    self.conv4 = nn.Conv2d(256, 256, (3,3), 1, 1)\n",
        "    self.maxpool3 = nn.MaxPool2d((1,2), 2)\n",
        "    self.conv5 = nn.Conv2d(256, 512, (3,3), 1, 1)\n",
        "    self.bn1 = nn.BatchNorm2d(512)\n",
        "    self.conv6 = nn.Conv2d(512, 512, (3,3), 1, 1)\n",
        "    self.bn2 = nn.BatchNorm2d(512)\n",
        "    self.maxpool4 = nn.MaxPool2d((1,2), 2)\n",
        "\n",
        "  def forward(self, x):\n"
      ],
      "metadata": {
        "id": "uoGYqJzfYRiL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}